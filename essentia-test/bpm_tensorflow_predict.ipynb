{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time music auto-tagging\n",
    "In this tutorial, we use Essentia's TensorFlow integration to perform auto-tagging in real-time.\n",
    "Additionally, this serves as an example of TensorFlow inference in streaming mode and can be easily adapted to work offline.\n",
    "\n",
    "\n",
    "## Setup\n",
    "To install Essentia with TensorFlow support, refer to the [Setup](https://essentia.upf.edu/tutorial_tensorflow_auto-tagging_classification_embeddings.html#setup) section of our previous *Music auto-tagging, classification, and embedding extraction* tutorial for instructions.\n",
    "\n",
    "Additionally, we rely on the `pysoundcard` package to capture the audio loopback of the system and feed Essentia in real-time. This way we can easily test our models with any music coming from our local player or browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip -q install pysoundcard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download `MusiCNN`,  one of our auto-tagging models. This and more models are available from the [Essentia models](https://essentia.upf.edu/models/)' site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -q https://essentia.upf.edu/models/autotagging/msd/msd-musicnn-1.pb\n",
    "# !wget -q https://essentia.upf.edu/models/autotagging/msd/msd-musicnn-1.json\n",
    "# !wget -q https://essentia.upf.edu/models/tempo/tempocnn/deepsquare-k16-3.json\n",
    "# !wget -q https://essentia.upf.edu/models/tempo/tempocnn/deepsquare-k16-3.pb\n",
    "# !wget -q https://essentia.upf.edu/models/tempo/tempocnn/deeptemp-k4-3.json\n",
    "# !wget -q https://essentia.upf.edu/models/tempo/tempocnn/deeptemp-k4-3.pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we import the required packages and Essentia algorithms.\n",
    "In this case, we use the TensorFlow functionalities in streaming mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 15:36:31.524131: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-14 15:36:31.524167: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-02-14 15:36:33.562318: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-14 15:36:33.563901: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-14 15:36:33.563914: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-14 15:36:33.563927: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (robin-Virtual-Machine): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from essentia.streaming import (\n",
    "    VectorInput,\n",
    "    FrameCutter,\n",
    "    TensorflowInputMusiCNN,\n",
    "    VectorRealToTensor,\n",
    "    TensorToPool,\n",
    "    TensorflowPredict,\n",
    "    PoolToTensor,\n",
    "    TensorToVectorReal,\n",
    "    TempoCNN,\n",
    "    TensorflowInputTempoCNN,\n",
    "    TensorflowPredictTempoCNN,\n",
    "    FrameToReal\n",
    ")\n",
    "from essentia import Pool, run, reset\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "import soundcard as sc\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib nbagg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the analysis parameters.\n",
    "To make this demo work in real-time, we tweaked some of the analysis parameters of `MusiCNN`.\n",
    "While it was trained on patches of size 187 (\\~3 seconds) we set `patch_size` to 64 (\\~1 second) to increase the prediction rate.\n",
    "You can experiment with the `patch_size` and `display_size` parameters to modify the prediction rate to your taste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('deeptemp-k4-3.json', 'r') as json_file:\n",
    "    metadata = json.load(json_file)\n",
    "\n",
    "model_file = 'deeptemp-k4-3.pb'\n",
    "input_layer = metadata['schema']['inputs'][0]['name']\n",
    "output_layer = metadata['schema']['outputs'][0]['name']\n",
    "\n",
    "# Analysis parameters.\n",
    "sample_rate = 11025\n",
    "frame_size = 1024 \n",
    "hop_size = 256\n",
    "n_bands = 40\n",
    "patch_size = 64\n",
    "display_size = 10\n",
    "\n",
    "buffer_size = patch_size * hop_size\n",
    "buffer_size = buffer_size * 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the algorithms. With this, we create a network similar to the one used inside `TensorflowPredictMusiCNN`, the wrapper algorithm presented in the previous tutorial. However, by instantiating the algorithms separately we gain additional control required for real-time usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] Successfully loaded graph file: `deeptemp-k4-3.pb`\n",
      "[   INFO   ] Successfully loaded graph file: `deeptemp-k4-3.pb`\n"
     ]
    }
   ],
   "source": [
    "buffer = np.zeros(buffer_size, dtype='float32')\n",
    "vimp = VectorInput(buffer)\n",
    "fc = FrameCutter(frameSize=frame_size, hopSize=hop_size)\n",
    "tim = TensorflowInputTempoCNN()\n",
    "vtt = VectorRealToTensor(shape=[1, 1, patch_size, n_bands],\n",
    "                         lastPatchMode='discard')\n",
    "ttp = TensorToPool(namespace=input_layer)\n",
    "tfp = TensorflowPredictTempoCNN(graphFilename=model_file,\n",
    "                        input=input_layer,\n",
    "                        output=output_layer)\n",
    "tempo = TempoCNN(graphFilename=model_file,\n",
    "                        input=input_layer,\n",
    "                        output=output_layer)\n",
    "ptt = PoolToTensor(namespace=output_layer)\n",
    "ttv = TensorToVectorReal()\n",
    "ftr = FrameToReal(frameSize=frame_size,\n",
    "                    hopSize=hop_size)\n",
    "pool = Pool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect the algorithms. We also store the mel-spectrograms in the `Pool` for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Kernel Error with TempoCNN: \n",
    "# vimp.data   >> fc.signal\n",
    "# fc.frame    >> tempo.audio\n",
    "# tempo.globalTempo   >>  (pool, 'global')\n",
    "# tempo.localTempo   >>  (pool, 'local')\n",
    "# tempo.localTempoProbabilities   >>  (pool, 'prob')\n",
    "\n",
    "vimp.data   >> tfp.signal\n",
    "tfp.predictions >> (pool, output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the plots and start processing the loopback stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpms = [x for x in range(1, 256)]\n",
    "\n",
    "def callback_console(data):\n",
    "    buffer[:] = data.flatten()\n",
    "\n",
    "    # Generate predictions.\n",
    "    reset(vimp)\n",
    "    run(vimp)\n",
    "    \n",
    "    print(pool.containsKey(output_layer))\n",
    "    \n",
    "    if pool.containsKey(output_layer):\n",
    "        index_max = np.argmax(softmax(20 * pool[output_layer][-1, :].T))\n",
    "        print(datetime.now())\n",
    "        print(bpms[index_max])\n",
    "\n",
    "\n",
    "    # Kernel Error: \n",
    "    # print(pool.containsKey(output_layer))\n",
    "    \n",
    "    # if pool.containsKey(output_layer):\n",
    "    #     print(datetime.now())\n",
    "    #     print(pool['global'][-1, :].T)\n",
    "    #     index_max = np.argmax(softmax(20 * pool['local'][-1, :].T))\n",
    "    #     print(bpms[index_max])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 15:37:00.733984: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3194045000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2022-02-14 15:37:01.507163\n",
      "95\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5830/2730818735.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_microphones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_loopback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mcallback_console\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumframes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/soundcard/pulseaudio.py\u001b[0m in \u001b[0;36mrecord\u001b[0;34m(self, numframes)\u001b[0m\n\u001b[1;32m    848\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mcaptured_frames\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnumframes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m                     \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m                     \u001b[0mcaptured_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                     \u001b[0mcaptured_frames\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/soundcard/pulseaudio.py\u001b[0m in \u001b[0;36m_record_chunk\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0mreadable_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pulse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pa_stream_readable_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreadable_bytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m             \u001b[0mreadable_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pulse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pa_stream_readable_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pool.clear()\n",
    "\n",
    "\n",
    "# Capture and process the speakers loopback.\n",
    "with sc.all_microphones(include_loopback=True)[0].recorder(samplerate=sample_rate) as mic:\n",
    "    while True:\n",
    "        callback_console(mic.record(numframes=buffer_size).mean(axis=1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
